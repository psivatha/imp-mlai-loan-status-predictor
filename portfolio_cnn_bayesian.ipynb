{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T20:38:22.158781Z",
     "start_time": "2024-07-31T20:38:22.135655Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from bayes_opt import BayesianOptimization\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n"
   ],
   "id": "6d5204cf2cc5e63f",
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.keras.wrappers'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[13], line 13\u001B[0m\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlayers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Dense, Conv1D, Flatten, Dropout\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01moptimizers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Adam\n\u001B[0;32m---> 13\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mwrappers\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mscikit_learn\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m KerasClassifier\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'tensorflow.keras.wrappers'"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T20:32:08.916861Z",
     "start_time": "2024-07-31T20:32:08.876497Z"
    }
   },
   "cell_type": "code",
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "train_df = pd.read_csv('data/loan_sanction_train.csv')\n",
    "\n",
    "# The original test file doesn't contain the Loan_Status field\n",
    "# Nevertheless loading it to construct a test set for another algorithm\n",
    "test_df = pd.read_csv('data/loan_sanction_test.csv')\n",
    "\n",
    "for df in [train_df, test_df]:\n",
    "    # Convert categorical variables into numeric\n",
    "    df['Gender'] = df['Gender'].map({'Male': 1, 'Female': 0})\n",
    "    df['Married'] = df['Married'].map({'Yes': 1, 'No': 0})\n",
    "    df['Education'] = df['Education'].map({'Graduate': 1, 'Not Graduate': 0})\n",
    "    df['Self_Employed'] = df['Self_Employed'].map({'Yes': 1, 'No': 0})\n",
    "    df['Property_Area'] = df['Property_Area'].map({'Urban': 2, 'Semiurban': 1, 'Rural': 0})\n",
    "    df['Dependents'] = df['Dependents'].replace('3+', 3)\n",
    "\n",
    "    # Fill missing values. Do it after converting categorical values into numeric\n",
    "    df['LoanAmount'].fillna(df['LoanAmount'].mean(), inplace=True)\n",
    "    df['Loan_Amount_Term'].fillna(df['Loan_Amount_Term'].mode()[0], inplace=True)\n",
    "    df['Credit_History'].fillna(df['Credit_History'].mode()[0], inplace=True)\n",
    "    df['Gender'].fillna(df['Gender'].mode()[0], inplace=True)\n",
    "    df['Married'].fillna(df['Married'].mode()[0], inplace=True)\n",
    "    df['Dependents'].fillna(df['Dependents'].mode()[0], inplace=True)\n",
    "    df['Self_Employed'].fillna(df['Self_Employed'].mode()[0], inplace=True)\n",
    "\n",
    "    # Create extra features that can be useful and meaningful\n",
    "    df['TotalIncome'] = df['ApplicantIncome'] + df['CoapplicantIncome']\n",
    "    df['LoanIncomeRatio'] = df['LoanAmount'] / df['TotalIncome']\n",
    "\n",
    "# Convert the output variable into numeric\n",
    "train_df['Loan_Status'] = train_df['Loan_Status'].map({'Y': 1, 'N': 0})\n",
    "X = train_df.drop(columns=['Loan_ID', 'Loan_Status'])\n",
    "y = train_df['Loan_Status']\n",
    "\n",
    "# Carry out train/test split from the given training data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ],
   "id": "fe22a73e3c1d9b",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T20:35:24.580258Z",
     "start_time": "2024-07-31T20:35:24.575525Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_cnn_model(learning_rate, dropout_rate, num_filters, kernel_size):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=int(num_filters), kernel_size=int(kernel_size), activation='relu', input_shape=(X_train.shape[1], 1)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(rate=dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n"
   ],
   "id": "37dfa74255f66985",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T20:35:31.021676Z",
     "start_time": "2024-07-31T20:35:31.011714Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def optimize_cnn(learning_rate, dropout_rate, num_filters, kernel_size):\n",
    "    model = KerasClassifier(build_fn=create_cnn_model,\n",
    "                            learning_rate=learning_rate,\n",
    "                            dropout_rate=dropout_rate,\n",
    "                            num_filters=num_filters,\n",
    "                            kernel_size=kernel_size,\n",
    "                            epochs=10,\n",
    "                            batch_size=10,\n",
    "                            verbose=0)\n",
    "\n",
    "    return cross_val_score(model, X_train, y_train, cv=3, scoring='accuracy').mean()\n"
   ],
   "id": "d77a43b46c4af4e4",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T20:35:36.940349Z",
     "start_time": "2024-07-31T20:35:36.937579Z"
    }
   },
   "cell_type": "code",
   "source": [
    "param_space = {\n",
    "    'learning_rate': (0.0001, 0.01),\n",
    "    'dropout_rate': (0.1, 0.5),\n",
    "    'num_filters': (10, 50),\n",
    "    'kernel_size': (2, 5)\n",
    "}\n"
   ],
   "id": "5bd600eec84e9dd4",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T20:35:43.521721Z",
     "start_time": "2024-07-31T20:35:43.501404Z"
    }
   },
   "cell_type": "code",
   "source": [
    "optimizer = BayesianOptimization(\n",
    "    f=optimize_cnn,\n",
    "    pbounds=param_space,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Start the optimization process\n",
    "optimizer.maximize(init_points=5, n_iter=25)\n"
   ],
   "id": "4eeb09293b7abaac",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BayesianOptimization' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m \u001B[43mBayesianOptimization\u001B[49m(\n\u001B[1;32m      2\u001B[0m     f\u001B[38;5;241m=\u001B[39moptimize_cnn,\n\u001B[1;32m      3\u001B[0m     pbounds\u001B[38;5;241m=\u001B[39mparam_space,\n\u001B[1;32m      4\u001B[0m     random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m\n\u001B[1;32m      5\u001B[0m )\n\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m# Start the optimization process\u001B[39;00m\n\u001B[1;32m      8\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mmaximize(init_points\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m, n_iter\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m25\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'BayesianOptimization' is not defined"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "best_params = optimizer.max['params']\n",
    "best_model = create_cnn_model(\n",
    "    learning_rate=best_params['learning_rate'],\n",
    "    dropout_rate=best_params['dropout_rate'],\n",
    "    num_filters=best_params['num_filters'],\n",
    "    kernel_size=best_params['kernel_size']\n",
    ")\n",
    "\n",
    "best_model.fit(X_train, y_train, epochs=50, batch_size=10, verbose=0)\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred = (y_pred > 0.5).astype(int)  # Convert probabilities to class labels\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Optimized CNN Accuracy: {accuracy}\")\n"
   ],
   "id": "2cf99ef2636dd08a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
