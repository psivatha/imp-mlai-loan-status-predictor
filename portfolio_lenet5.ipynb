{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-05T14:40:29.678470Z",
     "start_time": "2024-08-05T14:40:29.674316Z"
    }
   },
   "source": [
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from utils import preprocess_data, bayesian_optimisation"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T14:20:51.440422Z",
     "start_time": "2024-08-05T14:20:51.411332Z"
    }
   },
   "cell_type": "code",
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "X_train, X_test, y_train, y_test, train_df, test_df = preprocess_data(standardise=True)"
   ],
   "id": "56a63fb9ef0947a3",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Customise the data to be fed in terms of tensors",
   "id": "5bcdfed20917fc4d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T14:20:51.446137Z",
     "start_time": "2024-08-05T14:20:51.441950Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "class LoanDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y.values, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "train_dataset = LoanDataset(X_train, y_train)\n",
    "test_dataset = LoanDataset(X_test, y_test)"
   ],
   "id": "fa48f68a08d7ae7",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T14:20:51.450268Z",
     "start_time": "2024-08-05T14:20:51.447470Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ],
   "id": "858cc831d6556d91",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Customise a LeNet5 that was used to analyse image data to be used in this project ",
   "id": "6b6d6e8a1aa2f7c3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T20:04:59.597929Z",
     "start_time": "2024-08-06T20:04:59.546744Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TabularNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layers, dropout_rate, name=None):\n",
    "        super(TabularNet, self).__init__()\n",
    "        if name:\n",
    "            self.name = name\n",
    "        self.hidden_layers = nn.ModuleList()\n",
    "        last_size = input_size\n",
    "        for hidden_layer_size in hidden_layers:\n",
    "            self.hidden_layers.append(nn.Linear(last_size, hidden_layer_size))\n",
    "            self.hidden_layers.append(nn.Dropout(dropout_rate))\n",
    "            last_size = hidden_layer_size\n",
    "        self.output_layer = nn.Linear(last_size, 2)  # Output layer for binary classification\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.hidden_layers:\n",
    "            x = F.relu(layer(x))\n",
    "        x = self.output_layer(x)\n",
    "        return x"
   ],
   "id": "a3a38e167af0c72b",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The following function trains and evaluates the NN with specified hyperparameters and returns its accuracy\n",
    "\n"
   ],
   "id": "81c41da364c5f21c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T20:10:26.373697Z",
     "start_time": "2024-08-06T20:10:26.363827Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_and_evaluate(hidden_layer_sizes, learning_rate, dropout_rate, num_epochs=25):\n",
    "    model = TabularNet(input_size=X_train.shape[1], hidden_layers=hidden_layer_sizes, dropout_rate=dropout_rate)\n",
    "    # Loss funcrion optimiser\n",
    "    criterion = nn.CrossEntropyLoss()  # Classification\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Training loop\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()  # Set the model in evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():  # resource efficiency purpose\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    return accuracy\n"
   ],
   "id": "33a591ce0a8d04f2",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Obtain the hyperparameters for the best performing network",
   "id": "2a3ba37efd6b29e5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T14:21:26.746233Z",
     "start_time": "2024-08-05T14:20:51.464080Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def optimize_tabular_net(hidden_layer1, hidden_layer2, learning_rate, dropout_rate):\n",
    "    hidden_layers = [int(hidden_layer1), int(hidden_layer2)]\n",
    "    return train_and_evaluate(hidden_layers, learning_rate, dropout_rate)\n",
    "\n",
    "param_space = np.array([\n",
    "    (10, 100),  # hidden_layer1 size\n",
    "    (10, 100),  # hidden_layer2 size\n",
    "    (0.0001, 0.01),  # learning_rate\n",
    "    (0.1, 0.5)   # dropout_rate\n",
    "])\n",
    "\n",
    "n_iters = 25\n",
    "initial_samples = 5\n",
    "\n",
    "# Initial random samples\n",
    "x0 = np.random.uniform(param_space[:, 0], param_space[:, 1], size=(initial_samples, param_space.shape[0]))\n",
    "y0 = np.array([optimize_tabular_net(*params) for params in x0])\n",
    "\n",
    "gp_params = {\"alpha\": 1e-6}\n",
    "\n",
    "X_sample, Y_sample, gpr = bayesian_optimisation(n_iters, optimize_tabular_net, param_space, x0, y0.reshape(-1, 1), gp_params)\n",
    "\n",
    "# Best parameters\n",
    "best_idx = np.argmax(Y_sample)\n",
    "best_params = X_sample[best_idx]\n",
    "best_accuracy = Y_sample[best_idx]\n",
    "\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "print(f\"Best accuracy: {best_accuracy}\")\n"
   ],
   "id": "ea9fb7e0ba2e95a4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: [7.48656891e+01 1.00000000e+02 1.00000000e-04 1.00000000e-01]\n",
      "Best accuracy: [0.79674797]\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Train the network with the best hyperparameters to be used in predictions later",
   "id": "ae8909b67397e526"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T14:21:27.219734Z",
     "start_time": "2024-08-05T14:21:26.747991Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Use the best hyperparameters found from Bayesian Optimization\n",
    "best_hidden_layer1 = int(best_params[0])\n",
    "best_hidden_layer2 = int(best_params[1])\n",
    "best_learning_rate = best_params[2]\n",
    "best_dropout_rate = best_params[3]\n",
    "\n",
    "best_hidden_layers = [best_hidden_layer1, best_hidden_layer2]\n",
    "\n",
    "final_model = TabularNet(input_size=X_train.shape[1], hidden_layers=best_hidden_layers, dropout_rate=best_dropout_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(final_model.parameters(), lr=best_learning_rate)\n",
    "\n",
    "# Training the final model\n",
    "num_epochs = 25\n",
    "final_model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = final_model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "print(\"Final model trained.\")\n"
   ],
   "id": "946018ac0e6f2c39",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model trained.\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T14:21:27.228347Z",
     "start_time": "2024-08-05T14:21:27.221595Z"
    }
   },
   "cell_type": "code",
   "source": [
    "final_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = final_model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f\"Final model accuracy: {accuracy:.4f}\")\n"
   ],
   "id": "5a9b8d6b57cade01",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model accuracy: 0.7886\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Produce a validation dataset based on the network to be used by the other models in the project",
   "id": "a5ac0623f1b7f365"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T14:25:05.297065Z",
     "start_time": "2024-08-05T14:25:05.274952Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_test_final = test_df.drop(columns=['Loan_ID'])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_test_final_transformed = scaler.fit_transform(X_test_final)\n",
    "X_new_tensor = torch.tensor(X_test_final_transformed, dtype=torch.float32)\n",
    "\n",
    "final_model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = final_model(X_new_tensor)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    predictions = predicted.numpy()\n",
    "\n",
    "target_filename = \"data/loan_sanction_test_with_predictions_lenet5.csv\"\n",
    "test_df['Loan_Status'] = predictions\n",
    "\n",
    "test_df.to_csv(target_filename, index=False)\n",
    "\n",
    "print(f\"Predictions have been saved to {target_filename}.\")"
   ],
   "id": "8d5dcbf72ab65111",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions have been saved to data/loan_sanction_test_with_predictions_lenet5.csv.\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Cross validate this NN by means of the validation set produced by the other models' precitions\n",
    "\n",
    "## It can be seen that the models performs well with most of the data produced by the other models and exceptionally well against the validation data constructed usign LR"
   ],
   "id": "f00ba2c9969a319e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T20:48:27.084394Z",
     "start_time": "2024-08-06T20:48:26.905969Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for algo, filename in {\n",
    "    \"CNN\" : 'data/loan_sanction_test_with_predictions_cnn.csv',\n",
    "    \"DT\": 'data/loan_sanction_test_with_predictions_decision_tree.csv',\n",
    "    \"KNN\": 'data/loan_sanction_test_with_predictions_knn.csv',\n",
    "    \"LR\": 'data/loan_sanction_test_with_predictions_lr.csv',\n",
    "\n",
    "}.items():\n",
    "    test_df_new = pd.read_csv(filename)\n",
    "    X_new = test_df_new.drop(columns=['Loan_ID', 'Loan_Status'])\n",
    "    y_new = test_df_new['Loan_Status']\n",
    "    # Only scale for those that were scaled\n",
    "    scaler = StandardScaler()\n",
    "    X_new = scaler.fit_transform(X_new)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = final_model(X_new_tensor)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        y_pred = predicted.numpy()\n",
    "\n",
    "    y_pred = (y_pred > 0.5).astype(int)  # Convert probabilities to class labels\n",
    "\n",
    "    lr_accuracy = accuracy_score(y_new, y_pred)\n",
    "    lr_report = classification_report(y_new, y_pred)\n",
    "    print(f'LeNet5 Performance for {algo} produced predictions {lr_accuracy}')"
   ],
   "id": "1bae0795230e7bc2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet5 Performance for CNN produced predictions 0.16076294277929154\n",
      "LeNet5 Performance for DT produced predictions 0.9482288828337875\n",
      "LeNet5 Performance for KNN produced predictions 0.4713896457765668\n",
      "LeNet5 Performance for LR produced predictions 1.0\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6f958b736c5f3724"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
